{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "## *Data Science Unit 4 Sprint 3 Assignment 1*\n",
    "\n",
    "# Recurrent Neural Networks and Long Short Term Memory (LSTM)\n",
    "\n",
    "![Monkey at a typewriter](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Chimpanzee_seated_at_typewriter.jpg/603px-Chimpanzee_seated_at_typewriter.jpg)\n",
    "\n",
    "It is said that [infinite monkeys typing for an infinite amount of time](https://en.wikipedia.org/wiki/Infinite_monkey_theorem) will eventually type, among other things, the complete works of Wiliam Shakespeare. Let's see if we can get there a bit faster, with the power of Recurrent Neural Networks and LSTM.\n",
    "\n",
    "This text file contains the complete works of Shakespeare: https://www.gutenberg.org/files/100/100-0.txt\n",
    "\n",
    "Use it as training data for an RNN - you can keep it simple and train character level, and that is suggested as an initial approach.\n",
    "\n",
    "Then, use that trained RNN to generate Shakespearean-ish text. Your goal - a function that can take, as an argument, the size of text (e.g. number of characters or lines) to generate, and returns generated text of that size.\n",
    "\n",
    "Note - Shakespeare wrote an awful lot. It's OK, especially initially, to sample/use smaller data and parameters, so you can have a tighter feedback loop when you're trying to get things running. Then, once you've got a proof of concept - start pushing it more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "target_url = \"https://www.gutenberg.org/files/100/100-0.txt\"\n",
    "text = \"\"\n",
    "\n",
    "data = urllib.request.urlopen(target_url)\n",
    "for line in data:\n",
    "    text = text + \"\\n\" + str(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6946939"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequences: 2315633\n"
     ]
    }
   ],
   "source": [
    "# Split the text into runs of 40 characters each.\n",
    "maxlen = 40\n",
    "step = 3\n",
    "\n",
    "sequences = [] # X \n",
    "next_chars = [] # Y\n",
    "\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sequences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "\n",
    "print('sequences:', len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the text\n",
    "x = np.zeros((len(sequences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sequences), len(chars)), dtype=np.bool)\n",
    "\n",
    "for i, sequence in enumerate(sequences):\n",
    "    for t, char in enumerate(sequence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"s adore his beauty still,\\\\r\\\\n'\\nb'Attendi\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[3016]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "optimizer = RMSprop(learning_rate=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metric=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 8590008912667605811\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib \n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-gpu\n",
      "  Downloading https://files.pythonhosted.org/packages/63/13/ea9ff554aa0043540a2387c28dd7926575eb25cf89e598caecea836d189d/tensorflow_gpu-2.0.0-cp37-cp37m-win_amd64.whl (285.3MB)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\soobt\\anaconda3\\envs\\jupyterlab\\lib\\site-packages (from tensorflow-gpu) (0.33.6)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in c:\\users\\soobt\\anaconda3\\envs\\jupyterlab\\lib\\site-packages (from tensorflow-gpu) (1.16.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\soobt\\anaconda3\\envs\\jupyterlab\\lib\\site-packages (from tensorflow-gpu) (3.1.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in c:\\users\\soobt\\anaconda3\\envs\\jupyterlab\\lib\\site-packages (from tensorflow-gpu) (1.0.8)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in c:\\users\\soobt\\anaconda3\\envs\\jupyterlab\\lib\\site-packages (from tensorflow-gpu) (1.11.2)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\soobt\\anaconda3\\envs\\jupyterlab\\lib\\site-packages (from tensorflow-gpu) (1.12.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in c:\\users\\soobt\\anaconda3\\envs\\jupyterlab\\lib\\site-packages (from tensorflow-gpu) (3.10.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in c:\\users\\soobt\\anaconda3\\envs\\jupyterlab\\lib\\site-packages (from tensorflow-gpu) (0.1.8)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\soobt\\anaconda3\\envs\\jupyterlab\\lib\\site-packages (from tensorflow-gpu) (1.1.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in c:\\users\\soobt\\anaconda3\\envs\\jupyterlab\\lib\\site-packages (from tensorflow-gpu) (1.24.3)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\users\\soobt\\anaconda3\\envs\\jupyterlab\\lib\\site-packages (from tensorflow-gpu) (1.1.0)\n",
      "Requirement already satisfied: gast==0.2.2 in c:\\users\\soobt\\anaconda3\\envs\\jupyterlab\\lib\\site-packages (from tensorflow-gpu) (0.2.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.1.0,>=2.0.0 in c:\\users\\soobt\\anaconda3\\envs\\jupyterlab\\lib\\site-packages (from tensorflow-gpu) (2.0.1)\n",
      "Requirement already satisfied: astor>=0.6.0 in c:\\users\\soobt\\anaconda3\\envs\\jupyterlab\\lib\\site-packages (from tensorflow-gpu) (0.8.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in c:\\users\\soobt\\anaconda3\\envs\\jupyterlab\\lib\\site-packages (from tensorflow-gpu) (0.8.1)\n",
      "Requirement already satisfied: tensorboard<2.1.0,>=2.0.0 in c:\\users\\soobt\\anaconda3\\envs\\jupyterlab\\lib\\site-packages (from tensorflow-gpu) (2.0.1)\n",
      "Requirement already satisfied: h5py in c:\\users\\soobt\\anaconda3\\envs\\jupyterlab\\lib\\site-packages (from keras-applications>=1.0.8->tensorflow-gpu) (2.10.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\soobt\\anaconda3\\envs\\jupyterlab\\lib\\site-packages (from protobuf>=3.6.1->tensorflow-gpu) (41.6.0.post20191030)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\soobt\\anaconda3\\envs\\jupyterlab\\lib\\site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (0.16.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\soobt\\anaconda3\\envs\\jupyterlab\\lib\\site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (3.1.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\soobt\\anaconda3\\envs\\jupyterlab\\lib\\site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (0.4.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\soobt\\anaconda3\\envs\\jupyterlab\\lib\\site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (1.7.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\soobt\\anaconda3\\envs\\jupyterlab\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (1.2.0)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in c:\\users\\soobt\\anaconda3\\envs\\jupyterlab\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\soobt\\anaconda3\\envs\\jupyterlab\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (0.2.7)\n",
      "Requirement already satisfied: cachetools<3.2,>=2.0.0 in c:\\users\\soobt\\anaconda3\\envs\\jupyterlab\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (3.1.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\soobt\\anaconda3\\envs\\jupyterlab\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (3.1.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\soobt\\anaconda3\\envs\\jupyterlab\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (2.22.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\soobt\\anaconda3\\envs\\jupyterlab\\lib\\site-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (0.4.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\soobt\\anaconda3\\envs\\jupyterlab\\lib\\site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (2019.9.11)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\soobt\\anaconda3\\envs\\jupyterlab\\lib\\site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\soobt\\anaconda3\\envs\\jupyterlab\\lib\\site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (1.25.6)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\soobt\\anaconda3\\envs\\jupyterlab\\lib\\site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (3.0.4)\n",
      "Installing collected packages: tensorflow-gpu\n",
      "Successfully installed tensorflow-gpu-2.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ltj1je1fp5rO"
   },
   "outputs": [],
   "source": [
    "# TODO - Words, words, mere words, no matter from the heart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zE4a4O7Bp5x1"
   },
   "source": [
    "# Resources and Stretch Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uT3UV3gap9H6"
   },
   "source": [
    "## Stretch goals:\n",
    "- Refine the training and generation of text to be able to ask for different genres/styles of Shakespearean text (e.g. plays versus sonnets)\n",
    "- Train a classification model that takes text and returns which work of Shakespeare it is most likely to be from\n",
    "- Make it more performant! Many possible routes here - lean on Keras, optimize the code, and/or use more resources (AWS, etc.)\n",
    "- Revisit the news example from class, and improve it - use categories or tags to refine the model/generation, or train a news classifier\n",
    "- Run on bigger, better data\n",
    "\n",
    "## Resources:\n",
    "- [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) - a seminal writeup demonstrating a simple but effective character-level NLP RNN\n",
    "- [Simple NumPy implementation of RNN](https://github.com/JY-Yoon/RNN-Implementation-using-NumPy/blob/master/RNN%20Implementation%20using%20NumPy.ipynb) - Python 3 version of the code from \"Unreasonable Effectiveness\"\n",
    "- [TensorFlow RNN Tutorial](https://github.com/tensorflow/models/tree/master/tutorials/rnn) - code for training a RNN on the Penn Tree Bank language dataset\n",
    "- [4 part tutorial on RNN](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/) - relates RNN to the vanishing gradient problem, and provides example implementation\n",
    "- [RNN training tips and tricks](https://github.com/karpathy/char-rnn#tips-and-tricks) - some rules of thumb for parameterizing and training your RNN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
