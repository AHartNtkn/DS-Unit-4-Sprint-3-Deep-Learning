{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "## *Data Science Unit 4 Sprint 3 Assignment 1*\n",
    "\n",
    "# Recurrent Neural Networks and Long Short Term Memory (LSTM)\n",
    "\n",
    "![Monkey at a typewriter](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Chimpanzee_seated_at_typewriter.jpg/603px-Chimpanzee_seated_at_typewriter.jpg)\n",
    "\n",
    "It is said that [infinite monkeys typing for an infinite amount of time](https://en.wikipedia.org/wiki/Infinite_monkey_theorem) will eventually type, among other things, the complete works of Wiliam Shakespeare. Let's see if we can get there a bit faster, with the power of Recurrent Neural Networks and LSTM.\n",
    "\n",
    "This text file contains the complete works of Shakespeare: https://www.gutenberg.org/files/100/100-0.txt\n",
    "\n",
    "Use it as training data for an RNN - you can keep it simple and train character level, and that is suggested as an initial approach.\n",
    "\n",
    "Then, use that trained RNN to generate Shakespearean-ish text. Your goal - a function that can take, as an argument, the size of text (e.g. number of characters or lines) to generate, and returns generated text of that size.\n",
    "\n",
    "Note - Shakespeare wrote an awful lot. It's OK, especially initially, to sample/use smaller data and parameters, so you can have a tighter feedback loop when you're trying to get things running. Then, once you've got a proof of concept - start pushing it more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "target_url = \"https://www.gutenberg.org/files/100/100-0.txt\"\n",
    "text = \"\"\n",
    "\n",
    "data = urllib.request.urlopen(target_url)\n",
    "for line in data:\n",
    "    text = text + \"\\n\" + str(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6946939"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequences: 2315633\n"
     ]
    }
   ],
   "source": [
    "# Split the text into runs of 40 characters each.\n",
    "maxlen = 40\n",
    "step = 3\n",
    "\n",
    "sequences = [] # X \n",
    "next_chars = [] # Y\n",
    "\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sequences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "\n",
    "print('sequences:', len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the text\n",
    "x = np.zeros((len(sequences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sequences), len(chars)), dtype=np.bool)\n",
    "\n",
    "for i, sequence in enumerate(sequences):\n",
    "    for t, char in enumerate(sequence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"s adore his beauty still,\\\\r\\\\n'\\nb'Attendi\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[3016]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "optimizer = RMSprop(learning_rate=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metric=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "def on_epoch_end(epoch, _):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ltj1je1fp5rO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2315633 samples\n",
      "Epoch 1/5\n",
      "2315520/2315633 [============================>.] - ETA: 0s - loss: 1.3927\n",
      "----- Generating text after Epoch: 0\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"e all\\r\\n'\n",
      "b'    recreants and dastards,\"\n",
      "e all\\r\\n'\n",
      "b'    recreants and dastards, and the courses,\\r\\n'\n",
      "b'    The streath of the command and the beard and the procellents with his for the true of means of the hands and the world\\r\\n'\n",
      "b'    The part of the house and be the world and the world that the words,\\r\\n'\n",
      "b'That the worses the worses the world of the bear.\\r\\n'\n",
      "b'    The worse as the worse of the worsess and the heavents,\\r\\n'\n",
      "b'That the man and the worses and way the s\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"e all\\r\\n'\n",
      "b'    recreants and dastards,\"\n",
      "e all\\r\\n'\n",
      "b'    recreants and dastards, and where hath contrice,\\r\\n'\n",
      "b'    The worsest many for in enours, and some and is for the with the troth and more haw more in some your though but good all the first course\\r\\n'\n",
      "b'    Thou did a father and by the fame with the face;\\r\\n'\n",
      "b'                                                                                                                                                             \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"e all\\r\\n'\n",
      "b'    recreants and dastards,\"\n",
      "e all\\r\\n'\n",
      "b'    recreants and dastards, is worfivess,\\r\\n'\n",
      "b'    There-behes while there-not good boe and in inclean:\\r\\n'\n",
      "b'    Or a dangertening what Secas eyes.\\r\\n'\n",
      "b'\\r\\n'\n",
      "b'CABINCE.\\r\\n'\n",
      "b'A asaivon, Nor singte: Chock, and center\\r\\n'\n",
      "b'As anot, screng with your gartion, countrains\\r\\n'\n",
      "b'Some Tirs butter your busus;\\r\\n'\n",
      "b'mope strike unlioness unlessing ape\\xe2\\x80\\x99s forthomanass upon thy swordes,\\r\\n'\n",
      "b'If then in suciot, t\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"e all\\r\\n'\n",
      "b'    recreants and dastards,\"\n",
      "e all\\r\\n'\n",
      "b'    recreants and dastards, by my mellejoured fork Both.\\r\\n'\n",
      "b'  SICINIUS. Rurn magnes I troc,, your forwill, the holly\\r\\n'\n",
      "b'Took\\xe2\\x80\\x99d worses wouldst mana,\\r\\n'\n",
      "b'And ay, the handerou-st the day, Ropeotenhiato\\r\\n'\n",
      "b'Ceilew Thank fince, be, wall in thy wifors in to beWull audd\\r\\n'\n",
      "b'And shave mall! Was ' offend tare, sir, what was, by singrObPmalnam\\r\\n'\n",
      "b'Silver; and by kill, tor ortie, fow\\r\\n'\n",
      "b'Theor Talmust\n",
      "2315633/2315633 [==============================] - 1151s 497us/sample - loss: 1.3927\n",
      "Epoch 2/5\n",
      "2315392/2315633 [============================>.] - ETA: 0s - loss: 1.2890\n",
      "----- Generating text after Epoch: 1\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"by my troth,\\r\\n'\n",
      "b'      there\\xe2\\x80\\\"\n",
      "by my troth,\\r\\n'\n",
      "b'      there\\xe2\\x80\\x99s the breast of this this man that the more and the man that what he shall thing my some with the man with the princes the man with the man with the words.\\r\\n'\n",
      "b'\\r\\n'\n",
      "b'ANTONY.\\r\\n'\n",
      "b'What the man with the some friends and with my man the father,\\r\\n'\n",
      "b'    The more with the faith of the man that the sees of the more the some word,\\r\\n'\n",
      "b'    The will be some with the some word.\\r\\n'\n",
      "b'      \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"by my troth,\\r\\n'\n",
      "b'      there\\xe2\\x80\\\"\n",
      "by my troth,\\r\\n'\n",
      "b'      there\\xe2\\x80\\x99s his many dream.\\r\\n'\n",
      "b'    I will may that I must a brains the men with your strains\\r\\n'\n",
      "b'    The what so say your last bear thee sees this man to contrad to his charge,\\r\\n'\n",
      "b'    When the man thee shall sir, and what mean that here and strange and thing,\\r\\n'\n",
      "b'Thou shalt be the breath from him many still of his advice,\\r\\n'\n",
      "b'Which here see, sir, the sward me the friends of the man.\\r\\n'\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"by my troth,\\r\\n'\n",
      "b'      there\\xe2\\x80\\\"\n",
      "by my troth,\\r\\n'\n",
      "b'      there\\xe2\\x80\\x99s rewearts, give the\\r\\n'\n",
      "b'so consalper-wishast upless, I let your wastees\\r\\n'\n",
      "b'  Or wo onrinc on the ocmance, in their shoror;\\r\\n'\n",
      "b'If we is friend former'share,\\r\\n\"\n",
      "b\"    We have I sean the wenging fley unother,\\r\\n'\n",
      "b'For an astict in saugh'd will, I, please him.\\r\\n\"\n",
      "b\"    and but with worsg in else dass with th' friend?\\r\\n\"\n",
      "b'    Good field, and hamn in th' sir!\\r\\n\"\n",
      "b'    But so, m\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"by my troth,\\r\\n'\n",
      "b'      there\\xe2\\x80\\\"\n",
      "by my troth,\\r\\n'\n",
      "b'      there\\xe2\\x80\\x99s nyimvion, gentlems; and di; for live\\r\\n'\n",
      "b'Cresent'd.\\r\\n'\n",
      "b'\\r\\n'\n",
      "b'PARt HELENTESC_]\\r\\n\"\n",
      "b'  LPBEANCE. This enter vilalication welp, kieve;ve falles, you are told, was at hark\\r\\n'\n",
      "b'Even make lamb plaimt? Augk,t liear is. Gort\\xe2\\x80\\x99d, Luciuists.\\r\\n'\n",
      "b'\\r\\n'\n",
      "b'BRUTUS.\\r\\n'\n",
      "b'Wexd rouagly less the lowal.\\xe2\\x80\\x9d Dod'c\\r\\n\"\n",
      "b\"  rightre cride I turn to prayher'd me a owneg\\r\\n\"\n",
      "b' \n",
      "2315633/2315633 [==============================] - 932s 403us/sample - loss: 1.2890\n",
      "Epoch 3/5\n",
      "2315136/2315633 [============================>.] - ETA: 0s - loss: 1.3437\n",
      "----- Generating text after Epoch: 2\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"e glory fills the world with loud report\"\n",
      "e glory fills the world with loud report the father,\\r\\n'\n",
      "b'    The strong bear the beard and the beard of the the strong.\\r\\n'\n",
      "b'    The soul and the soul of the world with the world the soul\\r\\n'\n",
      "b'    That the thou be the more shall the man the prove and state,\\r\\n'\n",
      "b'    That be the strange court and the the face of the father,\\r\\n'\n",
      "b'    The strength of the beard the the beard of the strange with the beard of the strange and the mo\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"e glory fills the world with loud report\"\n",
      "e glory fills the world with loud report to the strange his same,\\r\\n'\n",
      "b'    And there eil the same to lant, and there the wind,\\r\\n'\n",
      "b'    And countriev with him and think the will, and then I be the soul\\r\\n'\n",
      "b'    and the I have an our the perin, sir, who that he ready;\\r\\n'\n",
      "b'And i a tell of the in the benefter force and come my lady,\\r\\n'\n",
      "b'    And to the court of many so all a your truth.\\r\\n'\n",
      "b'    Say I will have the present car\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"e glory fills the world with loud report\"\n",
      "e glory fills the world with loud reportly.\\r\\n'\n",
      "b'Uhdage the world of elouds ard updyngs, it is aforr\\r\\n'\n",
      "b'    Palf't! Then here sputes love of your libical-musine, put breath.\\r\\n'\n",
      "b'Uny the keep\\xe2\\x8"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\soobt\\Anaconda3\\envs\\jupyterlab\\lib\\site-packages\\ipykernel_launcher.py:6: RuntimeWarning: divide by zero encountered in log\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\\x99lls\\r\\n'\n",
      "b'As brumseon the sousines good many keep there come from his worne ariold\\r\\n'\n",
      "b'    What gentle to kill ers put samandy\\r\\n'\n",
      "b\"    Coreland of well-man, what is my late.\\r\\n'\n",
      "b\"  KINe?\\r\\n'\n",
      "b'Tloon an eyes the soul, hi\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"e glory fills the world with loud report\"\n",
      "e glory fills the world with loud reportly;\\r\\n\"\n",
      "b\"    Done got ye away and Yollubb'ans, no myy.\\r\\n'\n",
      "b'    Thou faith.\\r\\n'\n",
      "b'\\r\\n'\n",
      "b' [_Rein! againio, herm lest orbur,\\r\\n'\n",
      "b'As you, Gindaico-vance\\xe2\\x80\\x99s? O Ineng ehpour\\r\\n'\n",
      "b\"    thus to a ttemen with therabl down in\\r\\n'\n",
      "b\"    Why cut Berul is you curusgiyy from royor, want;\\r\\n'\n",
      "b'Dake him, welkey come, the eye, for I campar; and tear,\\r\\n'\n",
      "b'    couservick bhoodhing-bhoad 4\n",
      "2315633/2315633 [==============================] - 1083s 468us/sample - loss: 1.3437\n",
      "Epoch 4/5\n",
      "2315264/2315633 [============================>.] - ETA: 0s - loss: 1.5577\n",
      "----- Generating text after Epoch: 3\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"\n",
      "b'  MRS. PAGE.  [Aside]  Doctors doubt \"\n",
      "\n",
      "b'  MRS. PAGE.  [Aside]  Doctors doubt in the world be the portors,\\r\\"
     ]
    }
   ],
   "source": [
    "model.fit(x, y,\n",
    "          batch_size=128,\n",
    "          epochs=5,\n",
    "          callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zE4a4O7Bp5x1"
   },
   "source": [
    "# Resources and Stretch Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uT3UV3gap9H6"
   },
   "source": [
    "## Stretch goals:\n",
    "- Refine the training and generation of text to be able to ask for different genres/styles of Shakespearean text (e.g. plays versus sonnets)\n",
    "- Train a classification model that takes text and returns which work of Shakespeare it is most likely to be from\n",
    "- Make it more performant! Many possible routes here - lean on Keras, optimize the code, and/or use more resources (AWS, etc.)\n",
    "- Revisit the news example from class, and improve it - use categories or tags to refine the model/generation, or train a news classifier\n",
    "- Run on bigger, better data\n",
    "\n",
    "## Resources:\n",
    "- [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) - a seminal writeup demonstrating a simple but effective character-level NLP RNN\n",
    "- [Simple NumPy implementation of RNN](https://github.com/JY-Yoon/RNN-Implementation-using-NumPy/blob/master/RNN%20Implementation%20using%20NumPy.ipynb) - Python 3 version of the code from \"Unreasonable Effectiveness\"\n",
    "- [TensorFlow RNN Tutorial](https://github.com/tensorflow/models/tree/master/tutorials/rnn) - code for training a RNN on the Penn Tree Bank language dataset\n",
    "- [4 part tutorial on RNN](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/) - relates RNN to the vanishing gradient problem, and provides example implementation\n",
    "- [RNN training tips and tricks](https://github.com/karpathy/char-rnn#tips-and-tricks) - some rules of thumb for parameterizing and training your RNN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
